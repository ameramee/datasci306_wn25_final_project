---
title: "DataSci 306 Final Project"
author: "DataSci 306 Instructional Team"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Investigating the Internet Movie Database (IMDB)

The [Internet Movie Database (IMDb)]() contains information on millions of movies and television programs. They offer several [non-commercial use datasets](https://developer.imdb.com/non-commercial-datasets/) (documentation link). For this project we will analyze a **sample** of 100,000 titles from the IMDBb. 


## Part I: Preprocessing

* [Edit your `.gitignore` file](https://docs.github.com/en/get-started/getting-started-with-git/ignoring-files) to ignore all files with the `.rda` extension. (Add and commit)
* Create a new file in the `data/` directory called "Preprocessing.Rmd". The remaining instructions in this section are to be completed in that file.
* Write a function that will load a table from the IMDb files in the `data/` directory.
  * The function should take the file name (without the ".csv.gz" portion) as an argument
  * The function should load the appropriate `.csv.gz` file.
  * Make sure that all "\\N" values (which IMDB uses to indicate missing values) are turned into proper NA values in R
  * The function should return the table.
* For each of the `.csv.gz` files, use your function to load the table, then save it into a variable (e.g. `name_basics <- preprocess("name_basics")`) and use the `write_rds` function (e.g., `write_rds(name_basics, "name_basics.rda")`.
* Run the function on all of the `*_sample.csv.gz` files to created processed `.rda` files.
* In your other files, you can load these using the `TABLE <- read_rds("data/FILENAME.rda")` function.

## Part II: EDA of individual tables

```{r}
name_basics <- read_rds("data/name_basics_sample.rda")
title_basics <- read_rds("data/title_basics_sample.rda")
title_principals <- read_rds("data/title_principals_sample.rda")
title_ratings <- read_rds("data/title_ratings_sample.rda")
```

* For each of the 4 tables, perform basic exploratory data analysis. Report the following information:
  * For each quantitative column, provide some summary statistics
  * For any character columns, decided if they are actually representing factors/categorical data with a moderate number of columns. If so report the distributions for these variables.
  * Provide a plot for each table. Across all of the plots, try to show off the most possible different ggplot features (`geoms_` functions, `stat_` functions, coordinate systems, facets, use of several variables, annotations)
```{r}
summary(name_basics$birthYear)
summary(name_basics$deathYear)

table(name_basics$primaryProfession) |> head(15)

name_basics |>
  separate_rows(primaryProfession, sep = ",") |>
  count(primaryProfession, sort = TRUE) |>
  slice_max(n, n = 6) |>
  ggplot(aes(x = reorder(primaryProfession, n), y = n, fill = primaryProfession)) +
  geom_col() +
  labs(title = "Top 6 Professions", x = "Profession", y = "Count")
```
  
```{r}
summary(title_basics$startYear)
summary(title_basics$runtimeMinutes)

table(title_basics$titleType)

title_basics |>
  separate_rows(genres, sep = ",") |>
  filter(runtimeMinutes < 500) |>
  ggplot(aes(x = runtimeMinutes, fill = titleType)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~titleType, scales = "free_y") +
  theme_minimal() +
  labs(title = "Distribution of Runtime by Title Type") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
table(title_principals$category)

title_principals |>
  count(category, sort = TRUE) |>
  ggplot(aes(x = reorder(category, n), y = n)) +
  geom_bar(stat = "identity", fill = "blue") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Principal Category Counts", x = "Category", y = "Count")
```
```{r}
summary(title_ratings$averageRating)
summary(title_ratings$numVotes)

title_ratings |>
  filter(numVotes > 0) |>
  ggplot(aes(x = numVotes, y = averageRating)) +
  geom_point(alpha = 0.4, color = "green") +
  geom_smooth(method = "lm", color = "blue") +
  labs(title = "Ratings vs Number of Votes",
       x = "Number of Votes (log scale)", y = "Average Rating") +
  theme_minimal()
```

* For the `titles_basics` table
  * use two different variables to group and explore how `runtimeMinutes` varies for these different groups. Produce appropriate summaries.
```{r}
title_basics_clean <- title_basics |>
  filter(!is.na(runtimeMinutes) & runtimeMinutes > 0) |>
  separate_rows(genres, sep = ",")

runtime_summary <- title_basics_clean |>
  group_by(titleType, genres) |>
  summarise(
    count = n(),
    avg_runtime = mean(runtimeMinutes, na.rm = TRUE),
    median_runtime = median(runtimeMinutes, na.rm = TRUE),
    sd_runtime = sd(runtimeMinutes, na.rm = TRUE)
  ) |>
  arrange(desc(count))

print(runtime_summary)
```

  * How many titles are known for name that is different than the original release name? 7244
  * Graph the conditional distributions of release year based on the previous results. Comment on any trends you observe.
```{r}
diff_titles <- title_basics |>
  filter(primaryTitle != originalTitle)

print(nrow(diff_titles))

new_title_basics <- title_basics |>
  mutate(title_diff = ifelse(primaryTitle != originalTitle, "Different Name", "Same Name"))

ggplot(new_title_basics |> filter(!is.na(startYear)), aes(x = startYear, fill = title_diff)) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 50) +
  labs(
    title = "Distribution of Release Year by Title Match",
    x = "Release Year",
    y = "Count",
    fill = "Title Match"
  )

```

* For the ratings, use the `cut` function to break the data into three groups based on the average ratings. Are higher rated titles rated more often or less often than lower rated titles? 
They are rated slightly less often than lower rated titles.
```{r}
title_ratings <- title_ratings |>
  mutate(rating_group = cut(averageRating,
                            breaks = quantile(averageRating, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
                            include.lowest = TRUE,
                            labels = c("Low", "Medium", "High")))
summary(title_ratings)
ggplot(title_ratings, aes(x = rating_group, y = numVotes)) +
  geom_boxplot(fill = "red") +
  scale_y_log10() +
  labs(
    title = "Number of Votes by Rating Group",
    x = "Rating Group",
    y = "Number of Votes "
  )
```

* For the names table, 
  * Count the number of titles each person is known for and plot this distribution.
  * investigate the age of cast members
      * Group the data into living and deceased cast members. 
      * For deceased cast members, provide a graph that shows the distribution of ages.
      * Do the same for living cast members.
```{r}
name_basics <- name_basics |>
  mutate(num_known_titles = str_count(knownForTitles, ",") + 1)

name_basics$num_known_titles[is.na(name_basics$knownForTitles)] <- 0

ggplot(name_basics, aes(x = num_known_titles)) +
  geom_histogram(binwidth = 1, fill = "lightblue", color = "black") +
  scale_x_continuous(limits = c(0, 20)) +
  labs(
    title = "Distribution of Number of Known Titles per Person",
    x = "Number of Known Titles",
    y = "Number of People"
  )

name_basics_age <- name_basics |>
  mutate(
    birthYear = as.numeric(birthYear),
    deathYear = as.numeric(deathYear),
    is_alive = is.na(deathYear),
    age = ifelse(is_alive, 2025 - birthYear, deathYear - birthYear)
  ) |>
  filter(!is.na(age), age > 0 & age < 120)

ggplot(name_basics_age |> filter(!is_alive), aes(x = age)) +
  geom_histogram(binwidth = 3, fill = "skyblue", color = "black") +
  labs(
    title = "Age at Death of Deceased Cast Members",
    x = "Age",
    y = "Count"
  )

ggplot(name_basics_age |> filter(is_alive), aes(x = age)) +
  geom_histogram(binwidth = 5, fill = "green", color = "black") +
  labs(
    title = "Current Age of Living Cast Members (as of 2025)",
    x = "Age",
    y = "Count"
  )
```

* Find all the actors with first names "Tom", "Thomas", "Thom" or "Tomas". How many are there?
There are 3297
```{r}
names <- c("Tom", "Thomas", "Thom", "Tomas")

toms <- name_basics |>
  mutate(first_name = str_extract(primaryName, "^[^\\s]+")) |>
  filter(first_name %in% names)

n_toms <- nrow(toms)
print(n_toms)
```
* How many titles use alliteration (i.e., all words in the title start with the same letter)?
2895
```{r}
is_alliteration <- function(title) {
  words <- str_split(title, "\\s+")[[1]]
  words <- words[str_detect(words, "^[A-Za-z]")]
  if (length(words) < 2) return(FALSE)
  first_letters <- str_sub(words, 1, 1) |> str_to_lower()
  length(unique(first_letters)) == 1
}

title_alliteration <- title_basics |>
  filter(!is.na(primaryTitle)) |>
  mutate(alliterative = map_lgl(primaryTitle, is_alliteration))

n_alliterative <- sum(title_alliteration$alliterative)
print(n_alliterative)
```

## Part III: Pivoting

* Create a new version of the `titles_basics` table that has one row for each title-genre combination. See the `separate_rows` function for a useful too here.

```{r}
title_basics <- read_rds("data/title_basics_sample.rda")   # or load(...rda)

title_genre <- title_basics %>% 
  select(tconst, startYear, genres) %>% 
  filter(!is.na(genres), !is.na(startYear)) %>% 
  separate_rows(genres, sep = ",") %>%            # 1 row per title‑genre
  mutate(
    startYear = as.integer(startYear),            # keeps year clean
    genres     = trimws(genres)                   # removes leading spaces
  ) %>% 
  filter(genres != "")                            # drop blanks if any

glimpse(title_genre)
```


* Using that table, create a line plot of the count different genres over time (you may limit this to the most common genres if you wish).

```{r}
# 0.  Load the table (use .rds or load the .rda you created)
title_basics <- read_rds("data/title_basics_sample.rda")   # change if you used .rda

# 1.  Build the tall title‑genre table (one row per title–genre)
title_genre <- title_basics %>% 
  select(tconst, startYear, genres) %>% 
  filter(!is.na(startYear), !is.na(genres)) %>% 
  separate_rows(genres, sep = ",") %>%           # explode the genre list
  mutate(
    startYear = as.integer(startYear),           # ensure numeric year
    genres    = trimws(genres)                   # remove leading/trailing spaces
  ) %>% 
  filter(genres != "")                           # drop any blanks

# 2.  Identify the top‑8 genres overall
top_n <- 8
top_genres <- title_genre %>% 
  count(genres, sort = TRUE) %>% 
  slice_head(n = top_n) %>% 
  pull(genres)

# 3.  Aggregate yearly counts for those genres
genre_trend <- title_genre %>% 
  filter(genres %in% top_genres) %>% 
  group_by(startYear, genres) %>% 
  summarise(n_titles = n(), .groups = "drop")

# 4.  Plot
ggplot(genre_trend, aes(startYear, n_titles, colour = genres)) +
  geom_line(linewidth = 0.7) +
  labs(
    title  = "Most common genres over time",
    x      = "Release year",
    y      = "Number of titles",
    colour = "Genre"
  ) +
  theme_minimal()
```

* Use the `model.matrix` function in the following way: `model.matrix(yourtalltable, ~ genre - 1)` to create a wide table with one column for each genre. Use this table to find the most common pair of genres (hint: use the `cor` function or produce facet plots)
```{r}
library(tidyverse)
library(Matrix)

# tall table ------------------------------------------------------------
title_genre <- title_basics %>% 
  select(tconst, genres) %>% 
  filter(!is.na(genres)) %>% 
  separate_rows(genres, sep = ",") %>% 
  mutate(genres = trimws(genres)) %>% 
  filter(genres != "")

# one-hot matrix --------------------------------------------------------
mm <- model.matrix(~ genres - 1, data = title_genre)
colnames(mm) <- sub("^genres", "", colnames(mm))

# collapse to one row per film -----------------------------------------
incidence <- (rowsum(as.matrix(mm), group = title_genre$tconst) > 0) * 1

# co-occurrence counts --------------------------------------------------
co_cnt <- crossprod(incidence)
diag(co_cnt) <- 0

# tidy upper-triangle (each pair once) ---------------------------------
top_pair <- as.data.frame(as.table(co_cnt), stringsAsFactors = FALSE) %>% 
  rename(genre_1 = Var1, genre_2 = Var2, titles = Freq) %>% 
  filter(titles > 0, genre_1 < genre_2) %>%   # < now works on characters
  arrange(desc(titles)) %>% 
  slice(1)

top_pair
```

## Part IV: Joining Tables

* Join the table with one title-genre per row from the previous section with the ratings table.
  * What is the highest rated genre? What is the lowest rated genre?
```{r}
# join tall title-genre table with ratings ---------------------------
genre_ratings <- title_genre %>%          
  inner_join(title_ratings %>% 
               select(tconst, averageRating), 
             by = "tconst")

# average rating by genre -------------------------------------------
genre_summary <- genre_ratings %>% 
  group_by(genres) %>% 
  summarise(
    mean_rating = mean(averageRating, na.rm = TRUE),
    n_titles    = n(),
    .groups = "drop"
  ) %>% 
  arrange(desc(mean_rating))

# highest- and lowest-rated genres ----------------------------------
highest_genre <- genre_summary %>% slice_max(mean_rating, n = 1)
lowest_genre  <- genre_summary %>% slice_min(mean_rating, n = 1)

highest_genre   # highest rated
lowest_genre    # lowest rated
```

  * Using stacked bar charts, investigate the proportions of different genres over time. Are any incresing or decreasing? Use factor functions to help make the plots easier to read.
```{r}
library(forcats)

# ── 0· bring startYear back in ──────────────────────────────────────
tg_decade <- title_genre %>%                         # current tall tbl: tconst + genres
  left_join(title_basics %>%                         # add startYear via tconst
              select(tconst, startYear),
            by = "tconst") %>% 
  filter(!is.na(startYear), startYear >= 1900) %>%   # keep 1900+
  mutate(
    decade = as.factor(10 * floor(startYear / 10)),  # 1994 → "1990"
    genres = trimws(genres)
  )

# ── 1· keep the 10 most common genres, lump the rest ────────────────
top_10 <- tg_decade %>% 
  count(genres, sort = TRUE) %>% 
  slice_head(n = 10) %>% 
  pull(genres)

tg_decade <- tg_decade %>% 
  mutate(genres = fct_other(genres, keep = top_10),
         genres = fct_reorder(genres, genres, .fun = function(x) -length(x)))

# ── 2· stacked-bar plot of genre proportions by decade ──────────────
ggplot(tg_decade, aes(decade, fill = genres)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Proportion of genres by decade (top 10 + Other)",
       x = "Decade", y = "Share of titles", fill = "Genre") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Family appears to be decreasing, and short has dramtically decreased over the last 120 years. Documentaries have shown an increase over time, same with other.

* Join the `title_basics` with the ratings table. Have the number of ratings changed over time (based on release year)? Display graphically but also answer with numerical results.
```{r}

# Join with title_basics on tconst  ----------------------------------
titles_votes <- title_basics %>%        # assumes title_basics already in memory
  select(tconst, startYear) %>% 
  inner_join(title_ratings %>% 
               select(tconst, numVotes),
             by = "tconst") %>% 
  filter(!is.na(startYear), !is.na(numVotes))

# Total votes by release year  ---------------------------------------
votes_by_year <- titles_votes %>% 
  group_by(startYear) %>% 
  summarise(total_votes = sum(numVotes), .groups = "drop") %>% 
  arrange(startYear)

head(votes_by_year)
tail(votes_by_year)

# plot the trend -------------------------------
ggplot(votes_by_year, aes(startYear, total_votes)) +
  geom_line(color = "steelblue") +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Total IMDb votes per release year (sample)",
       x = "Release year", y = "Total number of votes") +
  theme_minimal()
```
The number of ratings have drastically changed over time. Starting with 872 votes in 1887 and getting to 2893610 votes in 2022. The number of votes appear to have decreased in recent years after increasing quite a bit over the last 120 years.



* Join the names with the ratings and the principals table. 
  * Group by individual people, find the top ten people based on the median rating of the titles they appear in.
```{r}
# join principals → ratings → names ─────────────────────────────
principal_ratings <- title_principals %>%                 # tconst–nconst links
  select(tconst, nconst) %>% 
  inner_join(title_ratings %>% 
               select(tconst, averageRating),             # add rating
             by = "tconst")

# median rating per person ─────────────────────────────────────-
person_median <- principal_ratings %>% 
  group_by(nconst) %>% 
  summarise(
    n_titles      = n(),
    median_rating = median(averageRating, na.rm = TRUE),
    .groups = "drop"
  ) %>% 
  filter(n_titles >= 3) %>%             # keep folks with ≥ 3 rated titles (adjust if desired)
  arrange(desc(median_rating))

# top-10 people, attach names & print ───────────────────────────
top10_people <- person_median %>% 
  slice_head(n = 10) %>% 
  left_join(name_basics %>% select(nconst, primaryName), by = "nconst") %>% 
  select(primaryName, n_titles, median_rating)

top10_people
```
  * Find the proportions of genres for the the titles that include the top 10 rated principals.
```{r}
# ── 0 · if person_median isn't in memory, rebuild it quickly ──────────
if (!exists("person_median")) {
  person_median <- title_principals %>% 
    select(tconst, nconst) %>% 
    inner_join(title_ratings %>% select(tconst, averageRating), by = "tconst") %>% 
    group_by(nconst) %>% 
    summarise(
      n_titles      = n(),
      median_rating = median(averageRating, na.rm = TRUE),
      .groups = "drop"
    ) %>% 
    filter(n_titles >= 3) %>% 
    arrange(desc(median_rating))
}

# get the nconst codes of the top-10 rated principals ───────────
top10_ids <- person_median %>% 
  slice_head(n = 10) %>% 
  pull(nconst)

# find all titles that feature at least one of those principals ─
titles_top10p <- title_principals %>% 
  filter(nconst %in% top10_ids) %>% 
  distinct(tconst)

# explode genres for those titles ──────────────────────────────
titles_top10p_genre <- titles_top10p %>% 
  inner_join(title_basics %>% select(tconst, genres),
             by = "tconst") %>% 
  separate_rows(genres, sep = ",") %>% 
  mutate(genres = trimws(genres)) %>% 
  filter(genres != "") %>% 
  distinct(tconst, genres)

# genre proportions among these titles ─────────────────────────
genre_props <- titles_top10p_genre %>% 
  count(genres, name = "n_titles") %>% 
  mutate(prop = n_titles / sum(n_titles)) %>% 
  arrange(desc(prop))

genre_props
```
  * Graph ratings against years. What trends do you see?
```{r}
library(tidyverse)

# 1 ── join year + rating  (same join as before, but we only keep columns we need)
ratings_year <- title_basics %>% 
  select(tconst, startYear) %>% 
  filter(!is.na(startYear)) %>% 
  inner_join(title_ratings %>% select(tconst, averageRating),
             by = "tconst")

# 2 ── yearly summary  (fast — only ~140 rows)
year_summary <- ratings_year %>% 
  group_by(startYear) %>% 
  summarise(
    n_titles      = n(),
    mean_rating   = mean(averageRating, na.rm = TRUE),
    median_rating = median(averageRating, na.rm = TRUE),
    .groups = "drop"
  )

# 3 ── plot: one point per year, line = mean trend
ggplot(year_summary, aes(startYear, mean_rating)) +
  geom_line(colour = "steelblue") +                 # smooth-ish line
  geom_point(aes(size = n_titles),                  # point size = # titles
             colour = "steelblue", alpha = 0.6) +
  scale_size_continuous(name = "Titles that year", range = c(0.5, 4)) +
  scale_y_continuous(limits = c(0, 10)) +
  labs(title = "Mean IMDb rating by release year (sample)",
       x = "Release year", y = "Mean rating") +
  theme_minimal()
```


* Create a table with one row for each person in the `name_basics` table and title they are known for. Join this to the ratings table to get the ratings of the "known for" films. Find the person (or people) who have the highest median known for rating.
```{r}
# One row per (person × known-for title) ---------------------------
knownfor_long <- name_basics %>% 
  select(nconst, primaryName, knownForTitles) %>% 
  filter(!is.na(knownForTitles)) %>% 
  separate_rows(knownForTitles, sep = ",") %>%          # explode to one tconst per row
  rename(tconst = knownForTitles)

# Attach each film’s rating ----------------------------------------
knownfor_rated <- knownfor_long %>% 
  inner_join(title_ratings %>% select(tconst, averageRating),
             by = "tconst")                             # drop films without ratings

# Median “known-for” rating per person -----------------------------
person_medians <- knownfor_rated %>% 
  group_by(nconst, primaryName) %>% 
  summarise(
    n_films       = n(),
    median_rating = median(averageRating, na.rm = TRUE),
    .groups = "drop"
  )

# Identify the highest median (may be ties) ------------------------
best_people <- person_medians %>% 
  filter(median_rating == max(median_rating))

best_people
```

* 

## Part V: Profiling and Parallel Processing

* These are large data sets (and yet only a sample of the entire IMDb!), so it make sense spend some time improving our code.
* Pick one or more of the previous problems and profile the performance of that piece. Write up your findings. If you see any opportunities to improve performance, feel fee to implement than and share the results.
* Select a previous computation that could be improved using parallelization and implement a parallelization solution. Using `system.time` show that parallelization improves performance.
* One task we performed involved counting items in strings separated by commas. Propose two different functions that could perform this taks. Compare them using bench marking. Which version would you recommend?

```{r all-funs-and-tests, echo=TRUE, message=FALSE}
# 1. Counting comma-separated items
count_items_strsplit <- function(x) {
  lengths(strsplit(x, ","))
}
count_items_gregexpr <- function(x) {
  sapply(gregexpr(",", x), function(pos) {
    if (pos[1] < 0) 1L else length(pos) + 1L
  })
}

# 2. Alliteration detection in titles
is_alliteration_base <- function(titles) {
  sapply(titles, function(title) {
    words <- unlist(strsplit(title, "\\s+"))
    words <- words[grepl("^[A-Za-z]", words)]
    if (length(words) < 2) return(FALSE)
    length(unique(tolower(substring(words, 1, 1)))) == 1
  })
}
is_alliteration_stringi <- function(titles) {
  if (!requireNamespace("stringi", quietly=TRUE)) install.packages("stringi")
  library(stringi)
  sapply(titles, function(title) {
    words <- stri_split_regex(title, "\\s+")[[1]]
    words <- words[stri_detect_regex(words, "^[A-Za-z]")]
    if (length(words) < 2) return(FALSE)
    first_letters <- stri_sub(words, 1, 1)
    length(unique(stri_trans_tolower(first_letters))) == 1
  })
}

# 3. Runtime summarization by (titleType, genre)
runtime_summary_dplyr <- function(df) {
  df %>%
    filter(!is.na(runtimeMinutes) & runtimeMinutes > 0) %>%
    separate_rows(genres, sep = ",") %>%
    mutate(runtimeMinutes = as.numeric(runtimeMinutes)) %>%
    group_by(titleType, genres) %>%
    summarise(
      count          = n(),
      avg_runtime    = mean(runtimeMinutes, na.rm = TRUE),
      median_runtime = median(runtimeMinutes, na.rm = TRUE),
      .groups        = "drop"
    )
}

runtime_summary_dt <- function(df) {
  if (!requireNamespace("data.table", quietly=TRUE)) install.packages("data.table")
  library(data.table)
  dt <- as.data.table(df)[!is.na(runtimeMinutes) & runtimeMinutes > 0]
  exploded <- dt[, .(genres = unlist(strsplit(genres, ","))), by = .(titleType, runtimeMinutes)]
  exploded[, .(
    count          = .N,
    avg_runtime    = mean(runtimeMinutes, na.rm = TRUE),
    median_runtime = median(runtimeMinutes, na.rm = TRUE)
  ), by = .(titleType, genres)]
}

# ---- Test calls ----
# A) Test counting functions
test_vec <- c("a,b,c", "d,e", "")
cat("strsplit counts: ", count_items_strsplit(test_vec), "\n")
cat("gregexpr counts:", count_items_gregexpr(test_vec), "\n\n")

# B) Test alliteration functions
test_titles <- c("Big Bad Wolf", "Crazy Cat", "Alpha Beta", "Solo")
cat("base alliteration:    ", is_alliteration_base(test_titles), "\n")
cat("stringi alliteration: ", is_alliteration_stringi(test_titles), "\n\n")

# C) If `title_basics` is loaded, test summaries on the first 50 rows
if (exists("title_basics")) {
  small_df <- head(title_basics, 50)
  cat("DPLYR summary (first 6 rows):\n")
  print(head(runtime_summary_dplyr(small_df), 6))
  cat("\nDATA.TABLE summary (first 6 rows):\n")
  print(head(runtime_summary_dt(small_df), 6))
}
```

Our side‐by‐side comparison of the two routines on a 50-row sample shows that both runtime_summary_dplyr() and runtime_summary_dt() produce exactly the same counts, average runtimes, and median runtimes for each genre (e.g. Documentary, Comedy, Adventure, Drama). The only discrepancy was in the order of the rows: the dplyr version printed groups in the sequence they appeared in the data, whereas data.table used its own grouping order. Because the numerical results agree perfectly, you can choose between them based on needs: use dplyr for clear, pipe-based code or data.table when you need maximum speed on large IMDb samples. To solidify these conclusions, the next step is to benchmark both implementations on the full 100 000-title dataset (and even parallelize the faster one) to quantify real‐world performance gains.

## Part VI: Shiny Applications

### Application 1

Using results from the previous section, create a shiny application that allows users to interact with the with the IMDb data. The application should use both interactive graphs and at least 3 widgets.

```{r}
library(shiny)
library(tidyverse)

# Load IMDb sample data
data.dir <- "data/"
name_basics      <- read_rds(file.path(data.dir, "name_basics_sample.rda"))
title_basics     <- read_rds(file.path(data.dir, "title_basics_sample.rda"))
title_principals <- read_rds(file.path(data.dir, "title_principals_sample.rda"))

ui <- fluidPage(
  titlePanel("Six Degrees of Kevin Bacon"),
  sidebarLayout(
    sidebarPanel(
      textInput("movie", "Enter movie or TV show title:"),
      actionButton("startBtn", "Start Game"),
      br(),
      uiOutput("selectPersonUI"),
      actionButton("nextBtn", "Next"),
      actionButton("resetBtn", "Reset Game")
    ),
    mainPanel(
      tableOutput("chain"),
      textOutput("message")
    )
  )
)

server <- function(input, output, session) {
  rv <- reactiveValues(
    step = 0,
    chain = tibble(Step = integer(), Person = character()),
    coactors = NULL,
    message = ""
  )

  # Start the game by loading cast of the entered movie
  observeEvent(input$startBtn, {
    req(input$movie)
    rv$step <- 1
    rv$chain <- tibble(Step = 1, Person = NA_character_)

    title_row <- title_basics %>%
      filter(str_to_lower(primaryTitle) == str_to_lower(input$movie))
    if (nrow(title_row) == 0) {
      rv$message <- paste0("Title '", input$movie, "' not found.")
      rv$step <- 0
      return()
    }
    tconst <- title_row$tconst[1]
    rv$coactors <- title_principals %>%
      filter(tconst == tconst) %>%
      left_join(name_basics, by = "nconst") %>%
      select(nconst, primaryName)
    rv$message <- paste0("Step 1: select a cast member from '", input$movie, "'.")
  })

  # Dynamic UI for selecting a person
  output$selectPersonUI <- renderUI({
    if (rv$step > 0 && rv$step <= 6 && !is.null(rv$coactors)) {
      selectInput(
        "person",
        label = paste0("Degree ", rv$step, ": choose a person"),
        choices = rv$coactors$primaryName,
        selected = NULL
      )
    }
  })

  # Handle Next button
  observeEvent(input$nextBtn, {
    req(rv$step > 0 && rv$step <= 6)
    sel_name <- input$person
    if (is.null(sel_name) || sel_name == "") return()

    # Find nconst of selected person
    sel_nconst <- rv$coactors$nconst[rv$coactors$primaryName == sel_name]
    rv$chain$Person[rv$chain$Step == rv$step] <- sel_name

    # Check for Kevin Bacon
    if (sel_nconst == 'nm0000102') {
      rv$message <- paste0("Congratulations! You reached Kevin Bacon in ", rv$step, " degrees.")
      rv$step <- 0
      return()
    }

    # Check if exceeded 6 steps
    if (rv$step == 6) {
      rv$message <- "Sorry, you've used 6 steps without reaching Kevin Bacon. You lose."
      rv$step <- 0
      return()
    }

    # Prepare next set of co-actors
    titles_played <- title_principals %>% filter(nconst == sel_nconst) %>% pull(tconst)
    next_coactors <- title_principals %>%
      filter(tconst %in% titles_played, nconst != sel_nconst) %>%
      distinct(nconst) %>%
      left_join(name_basics, by = "nconst") %>%
      select(nconst, primaryName)
    rv$coactors <- next_coactors

    # Increment step and update chain
    rv$step <- rv$step + 1
    rv$chain <- bind_rows(rv$chain, tibble(Step = rv$step, Person = NA_character_))
    rv$message <- paste0("Step ", rv$step, ": select someone who worked with ", sel_name, ".")
  })

  # Display the chain table
  output$chain <- renderTable({
    rv$chain
  })

  # Display status message
  output$message <- renderText({
    rv$message
  })

  # Reset game
  observeEvent(input$resetBtn, {
    rv$step <- 0
    rv$chain <- tibble(Step = integer(), Person = character())
    rv$coactors <- NULL
    rv$message <- "Game reset. Enter a new title to start."  
  })
}

shinyApp(ui, server)
```

### Application 2

In the principals table, there is a `category` column. Use this column as a primary filter to allow users to then select specific job categories. After select the specific job categories, display information from another table.

## Extra Credit: 6 Degrees of Kevin Bacon

Create an app to allow users to play [Six Degrees of Kevin Bacon](https://en.wikipedia.org/wiki/Six_Degrees_of_Kevin_Bacon#:~:text=Six%20Degrees%20of%20Kevin%20Bacon%20or%20Bacon's%20Law%20is%20a,ultimately%20leads%20to%20prolific%20American).

Create a Shiny application where a person can type the primary title of movie or TV show. Then have app show all the people who had a role in the show. Let the user select a person in that cast and show all other people who have been in a title with that person. Repeat up to 6 times. If "Kevin Bacon" (`nconst == 'nm0000102'`) ever appears in the list, let the player know they have won! If they click more than 6 times, let them know they have lost.
